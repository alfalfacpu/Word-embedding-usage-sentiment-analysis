{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2oFRkt9V3JY"
   },
   "source": [
    "#install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41fEkNZWF2nA",
    "outputId": "984dffb3-f25c-4283-fa20-52d84b1982b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oxa1yMkt0BX7",
    "outputId": "d4d5213f-96be-40fa-fbb7-260436b58f36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fasttext\n",
      "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
      "\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/68.8 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m30.7/68.8 kB\u001B[0m \u001B[31m1.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m68.8/68.8 kB\u001B[0m \u001B[31m1.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting pybind11>=2.2 (from fasttext)\n",
      "  Using cached pybind11-2.12.0-py3-none-any.whl (234 kB)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.25.2)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4227138 sha256=6d51a384ef22585902503424a7e9cd3153fb13bc6510d5838aa37241c73a686f\n",
      "  Stored in directory: /root/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n",
      "Successfully built fasttext\n",
      "Installing collected packages: pybind11, fasttext\n",
      "Successfully installed fasttext-0.9.2 pybind11-2.12.0\n"
     ]
    }
   ],
   "source": [
    "pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A5wN5rDVz-U_",
    "outputId": "ec11df5b-14dc-4159-a6e8-0d607438f2b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=9dd3f634b1d533be591adc001457f247428c21072b91f63b56a2d49f082b2279\n",
      "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Py9M26Czb4mG",
    "outputId": "f974ca1b-d557-4fd6-e29f-9f2ee7596ba4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5ks8JiTV-W0"
   },
   "source": [
    "#import"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FO4rAmMyzumB",
    "ExecuteTime": {
     "end_time": "2024-05-08T04:16:57.340796Z",
     "start_time": "2024-05-08T04:16:46.485049Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import shutil\n",
    "import os\n",
    "import nltk\n",
    "import requests\n",
    "import kagglehub\n",
    "import io\n",
    "import sklearn\n",
    "import fasttext\n",
    "import zipfile\n",
    "import gensim.downloader\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from gensim import models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.corpus import stopwords"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZ4p2vGGWGyP"
   },
   "source": [
    "#download models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTykh9rXWNam"
   },
   "source": [
    "##glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o1iKIBOKG9JQ",
    "outputId": "c8743fb0-fc39-4e9b-e9f0-49442db951ab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.2.5)\n",
      "Downloading from https://www.kaggle.com/api/v1/models/edithram23/glove/other/wordglove/1/download...\n",
      "100%|██████████| 509M/509M [00:05<00:00, 93.7MB/s]\n",
      "Extracting model files...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to model files: /root/.cache/kagglehub/models/edithram23/glove/other/wordglove/1\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.model_download(\"edithram23/glove/other/wordglove\")\n",
    "print(\"Path to model files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "FHCawM4PiAnN",
    "outputId": "cfd7df80-70f6-4764-c104-6bb2ee924c2b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/glove_model.txt'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define paths\n",
    "downloaded_files_dir = '/root/.cache/kagglehub/models/edithram23/glove/other/wordglove/1/glove.6B.200d.word2vec'\n",
    "project_dir = '/content'\n",
    "# Move file from downloaded directory to project directory\n",
    "shutil.move(downloaded_files_dir, os.path.join(project_dir, 'glove_model.txt'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOgjJA0kWRD6"
   },
   "source": [
    "##word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-BcwSTly4PUd",
    "outputId": "2b85c5e9-ba08-4af0-8c4e-27a453c321f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "word2vec_model = gensim.downloader.load('word2vec-google-news-300')\n",
    "word2vec_model.save_word2vec_format(\"word2vec_model.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wEwdWF6JWWLU"
   },
   "source": [
    "##fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EWpB4LUJwoR7",
    "outputId": "8c1f2b05-d843-4667-a863-406ca612aec7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-06 16:51:58--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M-subword.zip\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.162.163.11, 3.162.163.34, 3.162.163.19, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.162.163.11|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5828358084 (5.4G) [application/zip]\n",
      "Saving to: ‘crawl-300d-2M-subword.zip’\n",
      "\n",
      "crawl-300d-2M-subwo 100%[===================>]   5.43G  51.6MB/s    in 1m 58s  \n",
      "\n",
      "2024-05-06 16:53:57 (47.0 MB/s) - ‘crawl-300d-2M-subword.zip’ saved [5828358084/5828358084]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zip_file = \"crawl-300d-2M-subword.zip\"\n",
    "\n",
    "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M-subword.zip\n",
    "\n",
    "zip_path = \"/content/\" + zip_file\n",
    "\n",
    "extract_path = \"/content/\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "os.remove(zip_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWLfS4BbALww"
   },
   "source": [
    "#Defs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gt3bZGPh4Ksl"
   },
   "source": [
    "##def_load_word_embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ibJ0Ork7AFAO"
   },
   "outputs": [],
   "source": [
    "def load_word_embedding_model(model_type, model_path):\n",
    "    if model_type == \"word2vec\":\n",
    "        return KeyedVectors.load_word2vec_format(model_path, binary=True)\n",
    "    elif model_type == \"word2vec 2\":\n",
    "        return Word2Vec.load(word2vec_2_model_path)\n",
    "    elif model_type == \"glove\":\n",
    "        return KeyedVectors.load_word2vec_format(model_path)\n",
    "    elif model_type == \"fasttext\":\n",
    "        return fasttext.load_model(model_path)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type. Supported types: 'word2vec', 'word2vec 2', 'glove', 'fasttext'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTDipmYt4DMN"
   },
   "source": [
    "##def_create_feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "IgWxpSn2Btsd"
   },
   "outputs": [],
   "source": [
    "def create_feature_vectors(corpus, word_embedding_model):\n",
    "    review_vectors = []\n",
    "    for review in corpus:\n",
    "        words = review.split()\n",
    "        review_vector = np.zeros(word_embedding_model.vector_size)\n",
    "        count = 0\n",
    "        for word in words:\n",
    "            print(word_embedding_model)\n",
    "            if word in word_embedding_model:\n",
    "                review_vector += word_embedding_model[word]\n",
    "                count += 1\n",
    "        if count != 0:\n",
    "            review_vector /= count\n",
    "        review_vectors.append(review_vector)\n",
    "    X = np.vstack(review_vectors)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "0yQz5Bs2n4bY"
   },
   "outputs": [],
   "source": [
    "def create_feature_vectors_W2v(corpus, word_embedding_model):\n",
    "    review_vectors = []\n",
    "    for review in corpus:\n",
    "        words = review.split()\n",
    "        review_vector = np.zeros(word_embedding_model.vector_size)\n",
    "        count = 0\n",
    "        for word in words:\n",
    "            if word in word_embedding_model.wv.key_to_index:\n",
    "                review_vector += word_embedding_model.wv.get_vector(word)\n",
    "                count += 1\n",
    "        if count != 0:\n",
    "            review_vector /= count\n",
    "        review_vectors.append(review_vector)\n",
    "    X = np.vstack(review_vectors)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_GB2RuP38uJ"
   },
   "source": [
    "##clean_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "WPvC6pukuN1c"
   },
   "outputs": [],
   "source": [
    "def clean_reviews(no_reviews,language, words_to_be_excluded, words_to_be_included, dataset):\n",
    "\n",
    "    nltk.download('stopwords') #Must only be downloaded once\n",
    "     #Includes a list of words that souldn't appear in the reivews\n",
    "\n",
    "    #Create own list of stopwords\n",
    "    my_stopwords = stopwords.words(language)\n",
    "    #Append the words from to_be_excluded_words to my_stopwords\n",
    "    for word in words_to_be_excluded:\n",
    "        if not any ( word in stpwords for stpwords in my_stopwords):\n",
    "            my_stopwords.append(word)\n",
    "\n",
    "    #Remove words from my_stopwords that are present in to_be_included\n",
    "    for word in words_to_be_included:\n",
    "        if any (word in stpwords for stpwords in my_stopwords):\n",
    "            my_stopwords.remove(word)\n",
    "\n",
    "    #Stemming is the process of extracting the stem of each word e.g. \"loved\"->\"love\"\n",
    "\n",
    "\n",
    "    corpus =[] #Will contain the clean reviews\"\n",
    "    for i in range (0, no_reviews):\n",
    "        review = re.sub('[^a-zA-Z]',' ', dataset['Review'][i]) #Removes all other characters besides the letters and puts the review in a string\n",
    "        review = review.lower() #Transforms all UPPER-CASE characters to lower-case\n",
    "        review = review.split() #Separates all the words from the review string and puts them in a list\n",
    "        ps = PorterStemmer()\n",
    "        review = [ps.stem(word) for word in review if not word in set (my_stopwords)] #Remove irrelevant words from rewiews and stems all words\n",
    "        review = ' '.join(review)\n",
    "        corpus.append(review) #Append review string to corpus\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eb6-4kEQ3zhU"
   },
   "source": [
    "##Def_score_acc"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OHUhL6yo2VwM",
    "ExecuteTime": {
     "end_time": "2024-05-08T04:06:12.000094Z",
     "start_time": "2024-05-08T04:06:11.908142Z"
    }
   },
   "source": [
    "def score_acc(cm):\n",
    "    TN= cm[0][0] #True_Negative or results that were predicted to be negative and were negative\n",
    "    TP = cm[1][1]#True_Positive or results that were predicted to be positive and were positive\n",
    "\n",
    "    FN = cm[0][1] #False_Negative or results that were predicted to be negative but were positive\n",
    "    FP = cm [1][0]#False_Positive or results that were predicted to be positive but were negative\n",
    "    accuracy = (TP + TN)/(TP + TN + FP + FN) #Or correct_predictions/total_predictions\n",
    "    precision = TP / (TP + FP) #Or correct_positive_predictions/total_correct_predictions\n",
    "    recall = TP / (TP + FN)#Or correct_positive_predictions/(correct_positive_predictions + false_negative_predictions)\n",
    "    score = 2 * precision * recall/(precision + recall)\n",
    "    return accuracy,score"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cK4BJ5nq3uII"
   },
   "source": [
    "##Def_naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "OdKo4Jod2YO9"
   },
   "outputs": [],
   "source": [
    "#Applying the Naive Bayes classification algorithm\n",
    "def naive_bayes(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Making the Confusion Matrix\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred) #Contains results of predictions\n",
    "    accuracy,score=score_acc(cm)\n",
    "    print(\"Accuracy of the Naive Bayes algorithm is \",  accuracy, \" and score \", score)\n",
    "    return accuracy, score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BcuVW5LV3mgn"
   },
   "source": [
    "##Def_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "g17EFpdG2c5D"
   },
   "outputs": [],
   "source": [
    "def random_forest(number_of_trees, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    classifier = RandomForestClassifier(n_estimators = number_of_trees, criterion = 'entropy')\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Making the Confusion Matrix\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    accuracy,score=score_acc(cm)\n",
    "    print(\"Accuracy of the Random Forest algorithm for \", number_of_trees, \" is \",  accuracy, \" and score \", score)\n",
    "    return accuracy, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jekUhMRd3eOO"
   },
   "source": [
    "##Def_logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "EztpW05q2haj"
   },
   "outputs": [],
   "source": [
    "def logistic_regression(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    classifier = LogisticRegression(random_state = 0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predicting the Test set results\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Making the Confusion Matrix\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    accuracy,score=score_acc(cm)\n",
    "    print(\"Accuracy of the Logistic Regression algorithm is \",  accuracy, \" and score \", score)\n",
    "    return accuracy, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WyYqLOCvBcVW"
   },
   "source": [
    "##Def_demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uplcbidAU8ij"
   },
   "outputs": [],
   "source": [
    "# Set your parameters\n",
    "path = '/content/Restaurant_Reviews.tsv'\n",
    "language = 'english'\n",
    "words_to_be_included = ['not', 'nor', 'no']\n",
    "words_to_be_excluded = ['opinion']\n",
    "no_reviews = 1000\n",
    "test_set_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "GV7wK-PVVENg"
   },
   "outputs": [],
   "source": [
    "word2vec_model_path = '/content/word2vec_model.bin'\n",
    "word2vec_2_model_path = '/content/W2Vmodel.model'\n",
    "glove_model_path = '/content/glove_model.txt'\n",
    "fasttext_model_path = '/content/crawl-300d-2M-subword.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ndt9UquoZ7YT"
   },
   "outputs": [],
   "source": [
    "word2vec_model = load_word_embedding_model(\"word2vec\", word2vec_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "o1JDGOTNZ7Hc"
   },
   "outputs": [],
   "source": [
    "word2vec_2_model = load_word_embedding_model(\"word2vec 2\", word2vec_2_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "pMgP9rxeZ67q"
   },
   "outputs": [],
   "source": [
    "glove_model = load_word_embedding_model(\"glove\", glove_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c_az5ektVKxV"
   },
   "outputs": [],
   "source": [
    "# fasttext_model = load_word_embedding_model(\"fasttext\", fasttext_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "mXML6pTMVODS"
   },
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv(path, delimiter='\\t', quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jKM-SXNLVQiD",
    "outputId": "bf4ae1f4-7275-4ab2-a818-b2da4d127ea0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "corpus = clean_reviews(no_reviews, language, words_to_be_excluded, words_to_be_included, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3cGbJzNsVQei",
    "outputId": "49075b5f-9853-4836-95ac-8119aa5162ef"
   },
   "outputs": [],
   "source": [
    "X_word2vec = create_feature_vectors(corpus, word2vec_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "5oUfgACDVQbJ"
   },
   "outputs": [],
   "source": [
    "X_word2vec_2 = create_feature_vectors_W2v(corpus, word2vec_2_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OwaMl2auVQXs",
    "outputId": "aecf7525-6e39-457c-ba89-49c13028fa9a"
   },
   "outputs": [],
   "source": [
    "X_glove = create_feature_vectors(corpus, glove_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fNnxvFX0VQUL"
   },
   "outputs": [],
   "source": [
    "# X_fasttext = create_feature_vectors(corpus, fasttext_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "fphieDsrVQQ2"
   },
   "outputs": [],
   "source": [
    "y = dataset.iloc[:, 1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "PJgnViKoVQNW"
   },
   "outputs": [],
   "source": [
    "X_train_word2vec, X_test_word2vec, y_train, y_test = train_test_split(X_word2vec, y, test_size=test_set_size)\n",
    "X_train_word2vec_2, X_test_word2vec_2, _, _ = train_test_split(X_word2vec_2, y, test_size=test_set_size)\n",
    "X_train_glove, X_test_glove, _, _ = train_test_split(X_glove, y, test_size=test_set_size)\n",
    "# X_train_fasttext, X_test_fasttext, _, _ = train_test_split(X_fasttext, y, test_size=test_set_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ogGwQZMRVopB",
    "outputId": "2acd254d-01c0-4d87-8027-84ab92b2c77e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes - Word2Vec:\n",
      "Accuracy of the Naive Bayes algorithm is  0.675  and score  0.6285714285714286\n",
      "Naive Bayes - Word2Vec 2:\n",
      "Accuracy of the Naive Bayes algorithm is  0.51  and score  0.4367816091954023\n",
      "Naive Bayes - GloVe:\n",
      "Accuracy of the Naive Bayes algorithm is  0.51  and score  0.5148514851485149\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes - Word2Vec:\")\n",
    "accuracy_bayes_word2vec, score_bayes_word2vec = naive_bayes(X_train_word2vec, y_train, X_test_word2vec, y_test)\n",
    "print(\"Naive Bayes - Word2Vec 2:\")\n",
    "accuracy_bayes_word2vec_2, score_bayes_word2vec_2 = naive_bayes(X_train_word2vec_2, y_train, X_test_word2vec_2, y_test)\n",
    "print(\"Naive Bayes - GloVe:\")\n",
    "accuracy_bayes_glove, score_bayes_glove = naive_bayes(X_train_glove, y_train, X_test_glove, y_test)\n",
    "# print(\"Naive Bayes - FastText:\")\n",
    "# accuracy_bayes_fasttext, score_bayes_fasttext = naive_bayes(X_train_fasttext, y_train, X_test_fasttext, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y8nFp2COVtBF",
    "outputId": "f80a737a-6491-4940-9889-eb35b2165dda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Word2Vec:\n",
      "Accuracy of the Random Forest algorithm for  1000  is  0.7  and score  0.6875\n",
      "Random Forest - Word2Vec 2:\n",
      "Accuracy of the Random Forest algorithm for  1000  is  0.545  and score  0.5027322404371584\n",
      "Random Forest - GloVe:\n",
      "Accuracy of the Random Forest algorithm for  1000  is  0.47  and score  0.48543689320388345\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest - Word2Vec:\")\n",
    "accuracy_random_forest_word2vec, score_random_forest_word2vec = random_forest(1000, X_train_word2vec, y_train, X_test_word2vec, y_test)\n",
    "print(\"Random Forest - Word2Vec 2:\")\n",
    "accuracy_random_forest_word2vec_2, score_random_forest_word2vec_2 = random_forest(1000, X_train_word2vec_2, y_train, X_test_word2vec_2, y_test)  # اضافه شده\n",
    "print(\"Random Forest - GloVe:\")\n",
    "accuracy_random_forest_glove, score_random_forest_glove = random_forest(1000, X_train_glove, y_train, X_test_glove, y_test)\n",
    "# print(\"Random Forest - FastText:\")\n",
    "# accuracy_random_forest_fasttext, score_random_forest_fasttext = random_forest(1000, X_train_fasttext, y_train, X_test_fasttext, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1tr7-lwNVyIy",
    "outputId": "9d72f5e5-2c59-4652-dfc2-e2fa506465bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Word2Vec:\n",
      "Accuracy of the Logistic Regression algorithm is  0.735  and score  0.7195767195767195\n",
      "Logistic Regression - Word2Vec 2:\n",
      "Accuracy of the Logistic Regression algorithm is  0.535  and score  0.5550239234449761\n",
      "Logistic Regression - GloVe:\n",
      "Accuracy of the Logistic Regression algorithm is  0.52  and score  0.5151515151515151\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression - Word2Vec:\")\n",
    "accuracy_LR_word2vec, score_LR_word2vec = logistic_regression(X_train_word2vec, y_train, X_test_word2vec, y_test)\n",
    "print(\"Logistic Regression - Word2Vec 2:\")\n",
    "accuracy_LR_word2vec_2, score_LR_word2vec_2 = logistic_regression(X_train_word2vec_2, y_train, X_test_word2vec_2, y_test)\n",
    "print(\"Logistic Regression - GloVe:\")\n",
    "accuracy_LR_glove, score_LR_glove = logistic_regression(X_train_glove, y_train, X_test_glove, y_test)\n",
    "# print(\"Logistic Regression - FastText:\")\n",
    "# accuracy_LR_fasttext, score_LR_fasttext = logistic_regression(X_train_fasttext, y_train, X_test_fasttext, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nprB9Oh3V2cN",
    "outputId": "f25be54b-4c66-41f1-db7b-5066d6d9bce2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes - Word2Vec - Accuracy: 0.675 F1 Score: 0.6285714285714286\n",
      "Naive Bayes - Word2Vec 2 - Accuracy: 0.51 F1 Score: 0.4367816091954023\n",
      "Naive Bayes - GloVe - Accuracy: 0.51 F1 Score: 0.5148514851485149\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes - Word2Vec - Accuracy:\", accuracy_bayes_word2vec, \"F1 Score:\", score_bayes_word2vec)\n",
    "print(\"Naive Bayes - Word2Vec 2 - Accuracy:\", accuracy_bayes_word2vec_2, \"F1 Score:\", score_bayes_word2vec_2)\n",
    "print(\"Naive Bayes - GloVe - Accuracy:\", accuracy_bayes_glove, \"F1 Score:\", score_bayes_glove)\n",
    "# print(\"Naive Bayes - FastText - Accuracy:\", accuracy_bayes_fasttext, \"F1 Score:\", score_bayes_fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5sQ8dCJnV5Wo",
    "outputId": "fffdf114-42d4-4b61-82b6-26bcf300a383"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Word2Vec - Accuracy: 0.7 F1 Score: 0.6875\n",
      "Random Forest - Word2Vec 2 - Accuracy: 0.545 F1 Score: 0.5027322404371584\n",
      "Random Forest - GloVe - Accuracy: 0.47 F1 Score: 0.48543689320388345\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest - Word2Vec - Accuracy:\", accuracy_random_forest_word2vec, \"F1 Score:\", score_random_forest_word2vec)\n",
    "print(\"Random Forest - Word2Vec 2 - Accuracy:\", accuracy_random_forest_word2vec_2, \"F1 Score:\", score_random_forest_word2vec_2)\n",
    "print(\"Random Forest - GloVe - Accuracy:\", accuracy_random_forest_glove, \"F1 Score:\", score_random_forest_glove)\n",
    "# print(\"Random Forest - FastText - Accuracy:\", accuracy_random_forest_fasttext, \"F1 Score:\", score_random_forest_fasttext)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YCPMJkVxV8qu",
    "outputId": "1956c2bc-6984-442c-b9b2-48a38c9cd7db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Word2Vec - Accuracy: 0.735 F1 Score: 0.7195767195767195\n",
      "Logistic Regression - Word2Vec 2 - Accuracy: 0.535 F1 Score: 0.5550239234449761\n",
      "Logistic Regression - GloVe - Accuracy: 0.52 F1 Score: 0.5151515151515151\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression - Word2Vec - Accuracy:\", accuracy_LR_word2vec, \"F1 Score:\", score_LR_word2vec)\n",
    "print(\"Logistic Regression - Word2Vec 2 - Accuracy:\", accuracy_LR_word2vec_2, \"F1 Score:\", score_LR_word2vec_2)\n",
    "print(\"Logistic Regression - GloVe - Accuracy:\", accuracy_LR_glove, \"F1 Score:\", score_LR_glove)\n",
    "# print(\"Logistic Regression - FastText - Accuracy:\", accuracy_LR_fasttext, \"F1 Score:\", score_LR_fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "8cJ145IPEZ3-"
   },
   "outputs": [],
   "source": [
    "# def demo():\n",
    "    # # Set your parameters\n",
    "    # path = '/content/Restaurant_Reviews.tsv'\n",
    "    # language = 'english'\n",
    "    # words_to_be_included = ['not', 'nor', 'no']\n",
    "    # words_to_be_excluded = ['opinion']\n",
    "    # no_reviews = 1000\n",
    "    # test_set_size = 0.2\n",
    "\n",
    "    # Load word embedding models\n",
    "    word2vec_model_path = '/content/word2vec_model.bin'\n",
    "    word2vec_2_model_path = '/content/word2vec_model_window_10_dim_150_neg_10.bin'\n",
    "    glove_model_path = '/content/glove_model.txt'\n",
    "    fasttext_model_path = '/content/fasttext_model.bin.vectors.npy'\n",
    "\n",
    "\n",
    "    word2vec_model = load_word_embedding_model(\"word2vec\", word2vec_model_path)\n",
    "    word2vec_2_model = Word2Vec.load(\"word2vec 2\", word2vec_2_model_path)\n",
    "    glove_model = load_word_embedding_model(\"glove\", glove_model_path)\n",
    "    fasttext_model = load_word_embedding_model(\"fasttext\", fasttext_model_path)\n",
    "\n",
    "    # Importing the dataset\n",
    "    dataset = pd.read_csv(path, delimiter='\\t', quoting=3)\n",
    "\n",
    "    # Preprocessing reviews\n",
    "    corpus = clean_reviews(no_reviews, language, words_to_be_excluded, words_to_be_included, dataset)\n",
    "\n",
    "    # Creating feature vectors for Word2Vec\n",
    "    X_word2vec = create_feature_vectors(corpus, word2vec_model)\n",
    "\n",
    "    # Creating feature vectors for Word2Vec 2\n",
    "    X_word2vec_2 = create_feature_vectors(corpus, word2vec_2_model)\n",
    "\n",
    "    # Creating feature vectors for GloVe\n",
    "    X_glove = create_feature_vectors(corpus, glove_model)\n",
    "\n",
    "    # Creating feature vectors for FastText\n",
    "    X_fasttext = create_feature_vectors(corpus, fasttext_model)\n",
    "\n",
    "    y = dataset.iloc[:, 1].values\n",
    "\n",
    "    # Splitting the dataset into the Training set and Test set\n",
    "    X_train_word2vec, X_test_word2vec, y_train, y_test = train_test_split(X_word2vec, y, test_size=test_set_size)\n",
    "    X_train_word2vec_2, X_test_word2vec_2, _, _ = train_test_split(X_word2vec_2, y, test_size=test_set_size)\n",
    "    X_train_glove, X_test_glove, _, _ = train_test_split(X_glove, y, test_size=test_set_size)\n",
    "    X_train_fasttext, X_test_fasttext, _, _ = train_test_split(X_fasttext, y, test_size=test_set_size)\n",
    "\n",
    "    # Naive Bayes\n",
    "    print(\"Naive Bayes - Word2Vec:\")\n",
    "    accuracy_bayes_word2vec, score_bayes_word2vec = naive_bayes(X_train_word2vec, y_train, X_test_word2vec, y_test)\n",
    "    print(\"Naive Bayes - Word2Vec 2:\")\n",
    "    accuracy_bayes_word2vec_2, score_bayes_word2vec_2 = naive_bayes(X_train_word2vec_2, y_train, X_test_word2vec_2, y_test)\n",
    "    print(\"Naive Bayes - GloVe:\")\n",
    "    accuracy_bayes_glove, score_bayes_glove = naive_bayes(X_train_glove, y_train, X_test_glove, y_test)\n",
    "    print(\"Naive Bayes - FastText:\")\n",
    "    accuracy_bayes_fasttext, score_bayes_fasttext = naive_bayes(X_train_fasttext, y_train, X_test_fasttext, y_test)\n",
    "\n",
    "    # Random Forest\n",
    "    print(\"Random Forest - Word2Vec:\")\n",
    "    accuracy_random_forest_word2vec, score_random_forest_word2vec = random_forest(1000, X_train_word2vec, y_train, X_test_word2vec, y_test)\n",
    "    print(\"Random Forest - Word2Vec 2:\")\n",
    "    accuracy_random_forest_word2vec_2, score_random_forest_word2vec_2 = random_forest(1000, X_train_word2vec_2, y_train, X_test_word2vec_2, y_test)  # اضافه شده\n",
    "    print(\"Random Forest - GloVe:\")\n",
    "    accuracy_random_forest_glove, score_random_forest_glove = random_forest(1000, X_train_glove, y_train, X_test_glove, y_test)\n",
    "    print(\"Random Forest - FastText:\")\n",
    "    accuracy_random_forest_fasttext, score_random_forest_fasttext = random_forest(1000, X_train_fasttext, y_train, X_test_fasttext, y_test)\n",
    "\n",
    "    # Logistic Regression\n",
    "    print(\"Logistic Regression - Word2Vec:\")\n",
    "    accuracy_LR_word2vec, score_LR_word2vec = logistic_regression(X_train_word2vec, y_train, X_test_word2vec, y_test)\n",
    "    print(\"Logistic Regression - Word2Vec 2:\")\n",
    "    accuracy_LR_word2vec_2, score_LR_word2vec_2 = logistic_regression(X_train_word2vec_2, y_train, X_test_word2vec_2, y_test)\n",
    "    print(\"Logistic Regression - GloVe:\")\n",
    "    accuracy_LR_glove, score_LR_glove = logistic_regression(X_train_glove, y_train, X_test_glove, y_test)\n",
    "    print(\"Logistic Regression - FastText:\")\n",
    "    accuracy_LR_fasttext, score_LR_fasttext = logistic_regression(X_train_fasttext, y_train, X_test_fasttext, y_test)\n",
    "\n",
    "    print(\"Naive Bayes - Word2Vec - Accuracy:\", accuracy_bayes_word2vec, \"F1 Score:\", score_bayes_word2vec)\n",
    "    print(\"Naive Bayes - Word2Vec 2 - Accuracy:\", accuracy_bayes_word2vec_2, \"F1 Score:\", score_bayes_word2vec_2)\n",
    "    print(\"Naive Bayes - GloVe - Accuracy:\", accuracy_bayes_glove, \"F1 Score:\", score_bayes_glove)\n",
    "    print(\"Naive Bayes - FastText - Accuracy:\", accuracy_bayes_fasttext, \"F1 Score:\", score_bayes_fasttext)\n",
    "\n",
    "    print(\"Random Forest - Word2Vec - Accuracy:\", accuracy_random_forest_word2vec, \"F1 Score:\", score_random_forest_word2vec)\n",
    "    print(\"Random Forest - Word2Vec 2 - Accuracy:\", accuracy_random_forest_word2vec_2, \"F1 Score:\", score_random_forest_word2vec_2)\n",
    "    print(\"Random Forest - GloVe - Accuracy:\", accuracy_random_forest_glove, \"F1 Score:\", score_random_forest_glove)\n",
    "    print(\"Random Forest - FastText - Accuracy:\", accuracy_random_forest_fasttext, \"F1 Score:\", score_random_forest_fasttext)\n",
    "\n",
    "    print(\"Logistic Regression - Word2Vec - Accuracy:\", accuracy_LR_word2vec, \"F1 Score:\", score_LR_word2vec)\n",
    "    print(\"Logistic Regression - Word2Vec 2 - Accuracy:\", accuracy_LR_word2vec_2, \"F1 Score:\", score_LR_word2vec_2)\n",
    "    print(\"Logistic Regression - GloVe - Accuracy:\", accuracy_LR_glove, \"F1 Score:\", score_LR_glove)\n",
    "    print(\"Logistic Regression - FastText - Accuracy:\", accuracy_LR_fasttext, \"F1 Score:\", score_LR_fasttext)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqwRR7ep3H-6"
   },
   "source": [
    "#Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NsbO7Hf13HP-"
   },
   "outputs": [],
   "source": [
    "demo()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "H2oFRkt9V3JY",
    "F5ks8JiTV-W0",
    "MTykh9rXWNam",
    "uOgjJA0kWRD6",
    "wEwdWF6JWWLU",
    "b_GB2RuP38uJ",
    "eb6-4kEQ3zhU",
    "cK4BJ5nq3uII",
    "BcuVW5LV3mgn",
    "jekUhMRd3eOO"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
